---
layout: post
title:  "异步编程"
subtitle: "IO密集型编程方式"
date:   2018-07-15 20:30:13 -0400
background: '/img/posts/async/async.jpg'
categories: Programming
---
## 1 概念
异步为并发编程的一种模式，区别于同步编程，想要完全了解异步，得先从以下几个概念学起。

#### 1.1 并发（concurrency）
多指程序的组织结构，多个操作在同一时间段内进行。

#### 1.2 并行（parallelism）
指同一时间段内，多个工作单位在同时执行，典型的设计模式为多线程。

#### 1.3 异步
关于并发与并行的总结，并发是一种设计模式，强调组织的“同时执行”，并行则是实现并发的一种模式，强调执行单元的同时执行。由于在CPU的执行世界里，CPU的执行时间与IO阻塞时间完全不在一个量级上，所以当IO阻塞时，如果等待IO的结果，再调用下一个IO阻塞函数会浪费大量的时间，所以当IO阻塞时，不去等待结果，而是去调用下一个IO阻塞函数，等返回标志来到时，再去处理，会节省大量的时间，这样的操作方式为异步。而由于程序的执行时间大部分用于等待阻塞函数，不阻塞的程序部分在CPU里执行只是“一瞬间”，所以我们会觉得多个IO阻塞操作在“同时进行”。所以异步是并发设计的又一种模式。

## 2 异步同步对比
这里我们可以用下图来做对比：
![异步同步比较](/img/posts/async/async_sync.png)
可以看到，在同步编程中，程序的时间大多浪费在等待阻塞操作上，真正的CPU占用时间很少，当采用异步编程后，阻塞的时间大多重复在了一起，这样程序看起来像是并行运行（其实不是），实现了程序的并发设计。
## 3 异步与多线程对比
#### 3.1 异步与多线程开销对比
异步与多线程相比，虽然多线程是真正的并行执行，但是多线程上下文的切换的开销会比异步编程多一些，而且多线程保证数据的安全性（线程锁）比较复杂，很容易造成数据竞态条件，所以相比之下，异步上下文切换开销更小，所以在IO密集型程序上（文件的读写，网络编程），异步操作会更效率更高。

#### 3.2 Python 多线程缺陷
Python由于解释器不是完全线程安全的，所以会采用一个全局解释器锁（GIL）进行数据保护,也就是说Python多线程程序在同一时间内，只有一个线程在真正运行，只有在碰到IO阻塞时才会切换到另一个线程进行执行，所以Python的线程不是真正的多线程，虽然可以在IO阻塞的程序中执行多线程操作，但是上下文的切换开销还是让其效率低于异步编程。

## 4 异步框架
由于一般的异步-回调编程模式会陷入回调地狱（参考js），所以Python利用协程来实现异步编程。

#### 4.1 Python协程
协程，简单来说就是让使用异步+回调方式写的复杂代码，可以用类似同步的方式写出来，利用yield关键字来进行程序上下文状态的切换，可以理解为单线程中的“并发”。Python3以后，协程用asyncio异步IO模块支持，其关键操作包含以下几个概念：
- coroutine： 协程，使用```async```关键字来定义函数，声明为协程对象，需要注意的是协程的调用并不会立即执行函数，只是返回一个协程对象，只有将协程对象包装成```task```或```future```注册到事件循环中，由事件循环调用才能执行
- event_loop: 事件循环，讲协程注册到事件循环中，由事件循环进行协程对象的执行，当相应的事件发生时，调用相应的协程函数
- task：任务，它对协程进行了进一步的封装，包含了协程的各种状态
- future： 期物，它代表了将来要执行或未执行的任务的结果，跟task是同一性质的
- async： python3.5 用于定义协程函数的关键字
- await： python3.5用于挂起阻塞的异步调用接口
##### 4.2 Examples
下面我们来写一个简单的协程程序来看一下：

```
import time
import asyncio


async def io_work(x):
    print("task {} begin".format(x))
    ## simulate IO process
    await asyncio.sleep(1)
    print("task{} done".format(x))
    return "done {}".format(x)

start = time.time()
# set a event_loop
loop = asyncio.get_event_loop()
# set tasks
tasks = [ asyncio.ensure_future(io_work(i))for i in range(3)]
# register tasks in event loop
loop.run_until_complete(asyncio.wait(tasks))
end = time.time() - start
# show task.result()
for task in tasks:
    print(task.result())
print("done 3 task after {} s".format(end))
```
结果是
```
task 0 begin
task 1 begin
task 2 begin
task0 done
task1 done
task2 done
done 0
done 1
done 2
done 3 task after 1.001859426498413 s
```
如果是同步程序版本就是
```
import time

def io_work(x):
    print("task {} begin".format(x))
    # simulate IO process
    time.sleep(1)
    print("task{} done".format(x))
    return "done {}".format(x)

results = []
start = time.time()
for i in range(3):
    results.append(io_work(i))
end = time.time() - start
print("done 3 task after {} s".format(end))
```
结果是
```
task 0 begin
task0 done
task 1 begin
task1 done
task 2 begin
task2 done
done 3 task after 3.0037147998809814 s
```
可以看出同步和异步版本程序耗时差距较大，而且同步版本的时间消耗大多在
堵塞处，而异步解决了这个问题。

